{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropout effect.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9jG82R7skYXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a56b1b1c-88b1-4536-e6de-b5dc64a22e79"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "!pip install livelossplot --quiet # library to plot training logs\n",
        "from livelossplot import PlotLossesKeras\n",
        "\"Keras\", keras.__version__, \"tf\", tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Keras', '2.1.6', 'tf', '1.9.0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "gyAJBM57Giei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a936007-734c-4c08-cc5b-e8d46f6ceb31"
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "9d3G08oaoJFA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## loading in data\n",
        "\n",
        "doing a simple normalization of the data. since these are images, its pretty straightforward to use data augmentation too."
      ]
    },
    {
      "metadata": {
        "id": "z7YM6Zk-7W3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b3cf59c-5f75-4579-ba0d-0064ad90004f"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# simple norm\n",
        "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "#x_train.shape, x_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "#z-score norm\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 21s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M_XIWFkh5LR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "the things we need to build a NN model:"
      ]
    },
    {
      "metadata": {
        "id": "XlVuz3V3Doo9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iughb9g5Y-I4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train, augment=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoDj23JT6b3D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model(dropout=0):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), padding='same', activation='relu', \n",
        "                   input_shape=(32, 32, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  if dropout > 0: model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  if dropout > 0: model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='Adam',\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R3gMy5jZ7C0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2019
        },
        "outputId": "be0b6c63-f7d2-4635-96e1-7159c0aac77b"
      },
      "cell_type": "code",
      "source": [
        "dropouts = np.arange(0, 0.6, 0.1)\n",
        "history = []\n",
        "\n",
        "for dropout in dropouts:\n",
        "  model = make_model(dropout)\n",
        "  \n",
        "  hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=64), \n",
        "                    steps_per_epoch=len(x_train) / 64, \n",
        "                    epochs=25, validation_data=(x_test, y_test), \n",
        "                    callbacks=[PlotLossesKeras(), EarlyStopping(patience=4)])\n",
        "  \n",
        "  history.append(hist)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAExCAYAAAB7x+OdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XtclGX+//H3wIgHREVlMDXXcs1W\n0lI3C1EylECtzbVdxRKytYObpLlaKVm4sZKUuqV2ksoSaxfXJte+lXgoy8wDrq0KmxHuNxUs5SwI\nhSK/P/o2P02O16DDwOv5l/f5ms/cDy7fc1/3fVsqKysrBQAAAACoNw9XNwAAAAAA3BWBCgAAAAAM\nEagAAAAAwBCBCgAAAAAMEagAAAAAwBCBCgAAAAAMEajQaPTp00fffffdRdn3smXL9Pjjj1+UfZ/r\nu+++06hRo5Sbm9ug+12zZk2V84uLi3X77bfrlltuUUFBQYMe87///a9SU1MlSZs2bdLcuXON9/Wn\nP/1J//jHPxqqaQCAn4mIiNBvfvMbVzcDaJYIVEADmjdvnqZNm6bOnTs32D4rKir0zDPPVLnsq6++\nUmFhoTZu3ChfX98GO6Ykbd682RGoQkND9fTTTxvvKzY2VsuWLdPx48cbqnkAgP+TkZEhHx8fde3a\nVV988YWrmwM0OwQqNHo//PCDnnzySYWFhWnUqFFauHChKioqJEnbtm3TTTfdpFGjRik5OVkDBw5U\nVlZWjfs7duyYpkyZorCwMN16661at26dJOnMmTN6/PHHFRYWptDQUEVHR6ukpKTa+T+3f/9+/e//\n/q9Gjx4tSTp69KjuuusuhYaG6o477lB6errR8e+55x4VFxcrPDxcR48ePe9zzJ49W3l5eQoPD9eB\nAwfUt29fx/KsrCzHtN1u1/Tp0xUTE6OwsDCNHj1aX3/9tSQpPz9fU6dO1YgRI3Tbbbfps88+00cf\nfaRXXnlFq1at0sKFC2W32zV58mRJUmFhoWbMmOHYz4oVKxzH7NOnj9atW6exY8dq6NCheuONNyRJ\n7du312233aaVK1fW7UsHANTZu+++q/Dw8PP6FElat26dwsLCFBYWpkceeUTl5eXVzt+1a5dCQ0Md\n2547vWzZMs2bN0+/+93v9MYbb+js2bP685//rLCwMIWEhOiRRx7R6dOnJVXdp2zdulW33nrreW0e\nN26cNm/efLFLA1wSBCo0em+++aa+++47vf/++3r33Xe1Z88e/c///I8qKio0Z84cPfXUU/rwww/1\nzTffqKysrNb9PfHEExo8eLBSUlL0yiuv6C9/+YuysrL02WefKSsrSxs2bNDGjRv1y1/+Ul988UW1\n839uw4YNCgkJkYeHh+M4Y8aM0aZNm/THP/5Rjz76qNHx4+Pj5enpqQ0bNujyyy93HK9r165KSEjQ\nZZddpg0bNtR6herTTz/VnXfeqZSUFN1www168803JUmLFy9Wr169tGXLFiUkJGjWrFkaOnSoQkND\nFRUVpTlz5py3nyVLlqh9+/ZKSUnR22+/rb/97W/as2ePY3lmZqbWrVunF198UUuWLHGE31tuuUUb\nNmyo9fsBANRdRUWFNm3apLCwMI0YMUKffvqpysvLlZWVpYSEBK1atUobNmxQWVmZVq1aVe382nzy\nySdasWKFJk+erE2bNjn64g8//FDp6en64IMPJFXdpwwZMkQ5OTk6ePCgpB9/EDxy5IiCg4Mvam2A\nS4VAhUZv69atGj9+vKxWq1q1aqXbbrtN27dv1zfffKPy8nLddNNNkqTIyEidPXu2xn2dPn1an3/+\nue68805JUrdu3XTDDTdo586d6tixow4dOqRNmzaprKxMDz/8sIYNG1bt/J87cOCA+vXrJ+nHq2q7\ndu1y/CI3YsQIrVmzxuj4DaVXr1665pprJEl9+/bVt99+K+nHTvKndvbt21dbtmyRl5dXtfv55JNP\nHO3v0KGDQkNDtX37dsfy22+/XZIUEBCgH374QXl5eZKka665RidOnLho98kBQHP02WefqV+/fmrb\ntq1at26twYMH6+OPP9b27ds1YMAA+fv7y2KxaPHixZo8eXK182tz7bXXqmPHjpKksLAwvfPOO2rR\nooVatmypfv36OUZQVNenhIWF6f3335f045DyESNG1NjXAO6EQIVGLz8/X+3bt3dMt2/fXnl5eSoq\nKlK7du0c8202m+PfixcvVnh4uMLDw7V//37H/MLCQlVWVsrHx8cxr127dsrPz1f//v01b948JSUl\nKSgoSLNmzdLJkyernf9zeXl56tSpk+M4Z8+edRzHYrHI29vb6PgN5dxjenp6Oq4cFRYWnresbdu2\nNe4nPz//vLq3a9fOEZrOPY6np6ckOUKup6en47sDADQMu92urVu36te//rV+/etfa+PGjXr33XdV\nUFBw3t/qli1bymq1Vju/Nuf2w/n5+XrssccUFham8PBwbdmyRZWVlZKq71PGjBlzXqD6aXg80BQQ\nqNDode7cWYWFhY7pwsJCde7cWW3btlVpaalj/rlP1ps1a5Y2bNigDRs2qH///o75vr6+8vDwUFFR\n0Xn7+ykIhYeHKykpSR9//LHKysr02muv1Tj/XD91Jj8dx2KxOJ68V1lZqcOHD6tDhw5Gx68LT09P\nnT171tGOuoaxDh06nPeEwKysLMdY+KpU930AAC6toqIi7d69W7t27dKePXu0Z88epaam6sCBA/Lw\n8Djvb3tJSYlyc3Pl6+tb5fxzf2iTau5D/vrXv8pqteq9997Thg0bHCNFpOr7lOuvv15nzpzRxx9/\nrK+//lpDhgxpqDIALkegQqM3fPhwrV27VhUVFSotLdU///lP3XTTTerZs6fOnDmjXbt2SZL+9re/\nyWKx1Lgvq9WqoUOHKjk5WZJ05MgR7dmzR0OGDNE777yjF154QdKPHcKVV14pSdXO/7lOnTopPz9f\nkuTl5aWgoCC9++67kn58eMb999+vFi1a1Pv4LVq00NmzZ6t8EMa5fH195enpqa+++kqSzrsxuSYh\nISGOdmZmZmrcuHGqqKiQ1WpVcXHxBesPHz7c0f78/Hxt2rRJw4cPr/U4FRUVOnnypGPICADAOe+/\n/75uvPHG84bO/dTPlZeXa+/evcrKylJlZaViY2O1du1a3XTTTVXO9/PzU05OjvLy8lRRUaH33nuv\n2uPm5eXpqquukpeXlw4ePKgvvvjC8QNndX2Kh4eHRo8erbi4OIWEhKhFixYXtzjAJVT7NV7gEoqM\njHQMFZOkv/zlL4qMjNTRo0c1ZswYWSwWhYeHa9SoUbJYLJo/f77mzp0rHx8f3XPPPfLw8Kg1VP35\nz3/WvHnzZLfb1aJFC/3lL3/RZZddphEjRigmJka33HKLPD099Ytf/EILFy6UpGrnn6tfv346cOCA\nbrvtNknSggULNHv2bL399ttq3769Fi1aZHT8du3aadCgQbr55pv1yiuvaODAgVV+rlatWumhhx7S\nvffeK5vNpsjIyDrV/JFHHtFjjz2mkJAQeXt7a9GiRWrVqpVuvvlmzZ49W9nZ2ecFpocffljz589X\neHi4PDw8dP/99593FbA66enp6ty5sy677LI6tQsAULN169bp7rvvvmB+aGioXnzxRT311FO6++67\n5enpqX79+umee+5Ry5Ytq51/xx13aOzYseratatuv/12ffnll1Ue9w9/+IMee+wx2e12/frXv9Zj\njz2mxx9/XP3796+2T5F+HPa3cuVKhvuhybFUnjtOCXBjpaWlGjBggPbs2XPe+O1L5d///rceffRR\nbdiwwfGkP/x/S5YsUVlZ2SV5wTIAoPHJzc3Vb3/7W23duvW8H08Bd8f/+uDW7rjjDsejWj/44AP1\n6tXLJWFKkq677jp169ZNKSkpLjl+Y1ZcXKx169ZpypQprm4KAMBFli5dqokTJxKm0ORwhQpubc+e\nPXrqqaf0ww8/yNvbW/Pnz6/T8LOL5dixY7r33nuVlJTkeNAEfnxIyA033KDx48e7uikAgEssNzdX\nEyZMUJ8+fbRkyRLHEECgqSBQAQAAAIAhhvwBAAAAgKE6PeUvIyNDDz74oCZPnqxJkyadtywkJERd\nunRxjIddtGiRvvnmG82YMUO9e/eWJF111VV64oknajxGTs6Fj2duLnx926igoLT2FXEBaucc6meO\n2pnz83PNfY7OaM59lMT57gxqZ47amaN2zqlvP1VroCotLVVcXJwCAwOrXScxMVHe3t6O6W+++UaD\nBw/W0qVL69WY5spq5eZMU9TOOdTPHLVDc8L5bo7amaN25qjdpVXrkD8vLy8lJibKZrNdivYAAAAA\ngNuoNVBZrdZan8YSGxuriRMnatGiRfrpGReZmZmaOnWqJk6cqO3btzdMawEAAACgEanTPVQ1mT59\nuoYNG6b27dtr2rRpSklJ0YABAxQdHa1Ro0bp6NGjioqK0saNG+Xl5VXtfnx92zTry5PueE9BY0Ht\nnEP9zFE7AADgdKAaO3as49/BwcHKyMhQeHi4Ro8eLUnq0aOHOnfurOPHj+vyyy+vdj/N+cY5Pz+f\nZn/Dsylq5xzqZ47amSOIAgCaEqcem15cXKwpU6aovLxckpSamqrevXtr/fr1eu211yRJOTk5ysvL\nk7+/v/OtBQAAAIBGpNYrVGlpaUpISFB2drasVqtSUlIUEhKi7t27KzQ0VMHBwZowYYJatmypvn37\nKjw8XKdOndLs2bO1ZcsWnT59WvPnz69xuB8AAAAAuCNL5U9PkXCx5jx0hqFD5qidc6ifOWpnzh2H\n/DX375rz3Ry1M0ftzFE759S3n3JqyB8AAAAANGcEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAA\nAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKAC\nAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAw\nRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEPWuqyUkZGhBx98UJMnT9akSZPO\nWxYSEqIuXbrI09NTkrRo0SL5+/srPj5e+/btk8ViUUxMjPr379/wrQcANHs19TfV9VHr16/Xq6++\nKqvVqunTp2v48OEuaj0AwN3VGqhKS0sVFxenwMDAatdJTEyUt7e3Y3r37t06fPiwkpOTdejQIcXE\nxCg5OblhWgwAwP+pS3/z8z6qoKBAL7zwgt555x2VlpZq2bJlBCoAgLFah/x5eXkpMTFRNputzjvd\nsWOHRo4cKUnq1auXioqKVFJSYt5KAACqYNLf7NixQ4GBgWrbtq1sNpvi4uIuRVMBAE1UrVeorFar\nrNaaV4uNjVV2drYGDRqkWbNmKTc3VwEBAY7lHTt2VE5Ojtq2bVvtPnx928hq9axH05sWPz8fVzfB\nbVE751A/c9TO9erS3/y8j8rKytL333+vqVOn6uTJk3rooYdqHIUh0UdJnO/OoHbmqJ05anfp1Oke\nqppMnz5dw4YNU/v27TVt2jSlpKRcsE5lZWWt+ykoKHW2KW7Lz89HOTnFrm6GW6J2zqF+5qiduYvZ\nyf+8v6mujyosLNTy5ct17NgxRUVF6eOPP5bFYql2v825j5I4351B7cxRO3PUzjn17aecDlRjx451\n/Ds4OFgZGRmy2WzKzc11zD9x4oT8/PycPRQAAOeprb+pqo/q1q2bBgwYIKvVqh49esjb21v5+fnq\n1KnTJW07AKBpcOqx6cXFxZoyZYrKy8slSampqerdu7eCgoIcvwKmp6fLZrPVONwPAAATNfU31fVR\nQ4cO1c6dO3X27FkVFBSotLRUvr6+LvsMAAD3VusVqrS0NCUkJCg7O1tWq1UpKSkKCQlR9+7dFRoa\nquDgYE2YMEEtW7ZU3759FR4eLovFooCAAEVERMhisSg2NvZSfBYAQDMzcODAC/obu90uHx+fGvuo\nsLAwjR8/XpI0b948eXjwWkYAgBlLZV1ucLoEmvM4T8a5mqN2zqF+5qidOXe8Ubq5f9ec7+aonTlq\nZ47aOae+/RQ/yQEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEA\nAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgi\nUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAA\nABgiUAEAAACAIQIVAAAAABiqU6DKyMjQyJEjtXr16mrXWbx4sSIjIyVJu3bt0o033qjIyEhFRkYq\nLi6uYVoLAAAAAI2ItbYVSktLFRcXp8DAwGrXyczMVGpqqlq0aOGYN3jwYC1durRhWgkAAAAAjVCt\nV6i8vLyUmJgom81W7ToLFy7UzJkzG7RhAAAAANDY1XqFymq1ymqtfjW73a7BgwerW7du583PzMzU\n1KlTVVRUpOjoaAUFBdV4HF/fNrJaPevY7KbHz8/H1U1wW9TOOdTPHLUDAAC1BqqaFBYWym63a+XK\nlTp+/Lhjfs+ePRUdHa1Ro0bp6NGjioqK0saNG+Xl5VXtvgoKSp1pilvz8/NRTk6xq5vhlqidc6if\nOWpnjiAKAGhKnHrK386dO5Wfn6+77rpL0dHRSk9PV3x8vPz9/TV69GhZLBb16NFDnTt3Pi9wAQAA\nAEBT4NQVqvDwcIWHh0uSsrKyNHfuXMXExGj9+vXKycnRlClTlJOTo7y8PPn7+zdIgwEAAACgsag1\nUKWlpSkhIUHZ2dmyWq1KSUlRSEiIunfvrtDQ0Cq3CQkJ0ezZs7VlyxadPn1a8+fPr3G4HwAAAAC4\nI0tlZWWlqxshqVnfi8C9GOaonXOonzlqZ84d76Fq7t8157s5ameO2pmjds6pbz/l1JA/AABcLT4+\nXvv27ZPFYlFMTIz69+/vWBYSEqIuXbrI0/PHp8guWrTIMQT9+++/16233qoHH3xQ48aNc0nbAQDu\nj0AFAHBbu3fv1uHDh5WcnKxDhw4pJiZGycnJ562TmJgob2/vC7Z96aWX1L59+0vVVABAE+XUU/4A\nAHClHTt2aOTIkZKkXr16qaioSCUlJbVud+jQIWVmZmr48OEXuYUAgKaOK1QAALeVm5urgIAAx3TH\njh2Vk5Ojtm3bOubFxsYqOztbgwYN0qxZs2SxWJSQkKAnnnhC69atq9NxmvvL5yX3vPetsaB25qid\nOWp36RCoAABNxs+fszR9+nQNGzZM7du317Rp05SSkqLvv/9e1113nS6//PI677c5v3xe4gZ3Z1A7\nc9TOHLVzDg+lAAA0GzabTbm5uY7pEydOyM/PzzE9duxYx7+Dg4OVkZGh//73vzp69Ki2bt2q7777\nTl5eXurSpYuGDBlySdsOAGgauIcKAOC2goKClJKSIklKT0+XzWZzDPcrLi7WlClTVF5eLklKTU1V\n79699dxzz+mdd97RmjVr9Pvf/14PPvggYQoAYIwrVAAAtzVw4EAFBAQoIiJCFotFsbGxstvt8vHx\nUWhoqIKDgzVhwgS1bNlSffv2VXh4uKubDABoYnixbyPAOFdz1M451M8ctTPnjjdKN/fvmvPdHLUz\nR+3MUTvn1LefYsgfAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIV\nAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACA\nIQIVAAAAABiqU6DKyMjQyJEjtXr16mrXWbx4sSIjIx3T8fHxmjBhgiIiIrR//37nWwoAAAAAjUyt\ngaq0tFRxcXEKDAysdp3MzEylpqY6pnfv3q3Dhw8rOTlZCxYs0IIFCxqmtQAAAADQiNQaqLy8vJSY\nmCibzVbtOgsXLtTMmTMd0zt27NDIkSMlSb169VJRUZFKSkoaoLkAAAAA0HhYa13BapXVWv1qdrtd\ngwcPVrdu3RzzcnNzFRAQ4Jju2LGjcnJy1LZt22r34+vbRlarZ13b3eT4+fm4uglui9o5h/qZo3YA\nAKDWQFWTwsJC2e12rVy5UsePH692vcrKylr3VVBQ6kxT3Jqfn49ycopd3Qy3RO2cQ/3MUTtzBFEA\nQFPiVKDauXOn8vPzddddd6m8vFxHjhxRfHy8bDabcnNzHeudOHFCfn5+TjcWAAAAABoTpx6bHh4e\nrg8++EBr1qzR8uXLFRAQoJiYGAUFBSklJUWSlJ6eLpvNVuNwPwAAAABwR7VeoUpLS1NCQoKys7Nl\ntVqVkpKikJAQde/eXaGhoVVuM3DgQAUEBCgiIkIWi0WxsbEN3nAAAAAAcDVLZV1ucLoEmvO9CNyL\nYY7aOYf6maN25tzxHqrm/l1zvpujduaonTlq55z69lNODfkDAAAAgOaMQAUAAAAAhghUAOAmtm7d\nUqf1nn9+sY4dy652+Zw5f2qoJgEA4NBc+ykCFQC4gW+/PabNm1PqtO6MGbPUtWu3apcvXLikoZoF\nAICk5t1POfUeKgDApbFkSYK+/DJdw4Zdr1tuGaVvvz2m5557UU8//ZRyck6orKxMf/jD/QoKGqbo\n6Pv1pz89qo8/3qJTp0p05MhhZWdnafr0WQoMDNKYMSP0/vtbFB19v66//gbt3btHhYWFSkj4qzp3\n7qynnnpC3333rfr166+PPtqsd9/9wNUfHwDQyDXnfopABQD1tOajTO39OkcVFQ33kNTrr7ZpfMgv\nq10+cWKk7PY1uuKKXjpy5Bu9+OKrKijI1+DBN2rUqFuVnZ2lJ56Yo6CgYedtd+LEcS1atFQ7d36u\nf/7zHQUGBp233NvbW88//5JeemmZPv30I3Xt2l3l5T9oxYo3tH37Nq1Z87cG+4wAgEvj9ffS9ene\nrAbdJ/1U9QhUAOBmfvWrAEmSj087ffllutavt8ti8dDJk0UXrNu//3WSJJvNppKSkguWX3vtAMfy\noqIiHT78v+rX71pJUmBgkDw9PS/WxwAANFHNrZ8iUAFAPY0P+aWmTRjgsnd8tGjRQpK0adMGnTx5\nUi+88KpOnjype++NvGDdczuaql47+PPllZWV8vD4cZ7FYpHFYmno5gMALrI/3Bag227s4bLjN7d+\nikAFAG7Aw8NDFRUV580rLCzUZZd1lYeHhz755COdPn3a6eN069bd8ZSm3bt3XnDMxig+Pl779u2T\nxWJRTEyM+vfv71gWEhKiLl26ODrkRYsWyd/fX88884z+9a9/6cyZM3rggQd0yy23uKr5ANAkNOd+\niqf8AYAb+MUvrtBXXx3UqVP/fzjE8OEh+vzzbZox449q3bq1bDabVq5MdOo4Q4YM06lTp/THP07R\nvn1fqF279s42/aLavXu3Dh8+rOTkZC1YsEALFiy4YJ3ExEQlJSUpKSlJ/v7+2rlzp77++mslJyfr\n1VdfVXx8vAtaDgBNS3PupyyVVV1bcwFXDZ1pDPz8fJr153cGtXMO9TPXVGt38mSR9u7do+HDRygn\n54RmzPij3n77nQY9hp+fT4Pt6/nnn1fXrl31+9//XpIUHh6utWvXqm3btpJ+vEL13nvvydvb27FN\nRUWFfvjhB7Vp00YVFRUaMmSIPv/88xrH4TfF77o+mur5filQO3PUzlxTrl1j7KcY8gcAcGjTxlsf\nfbRZb7+dpMrKs3roocb9csXc3FwFBAQ4pjt27KicnBxHoJKk2NhYZWdna9CgQZo1a5Y8PT3Vpk0b\nSdLatWsVHBxc603Nvr5tZLW6/sZnV2rIINzcUDtz1M5cU61dhw6ttGzZVv3jH2/r7NmzmjfvcZd/\nVgIVAMDBarXqqaeednUzjP180MX06dM1bNgwtW/fXtOmTVNKSorCw8MlSZs3b9batWv1+uuv17rf\ngoLSi9Jed9GUf+2+2KidOWpnrqnX7vHH486bbujPWt+Axj1UAAC3ZbPZlJub65g+ceKE/Pz8HNNj\nx45Vp06dZLVaFRwcrIyMDEnStm3b9PLLLysxMVE+Pk3zV1wAwKVBoAIAuK2goCClpKRIktLT02Wz\n2RzD/YqLizVlyhSVl5dLklJTU9W7d28VFxfrmWee0SuvvKIOHTq4rO0AgKaBIX8AALc1cOBABQQE\nKCIiQhaLRbGxsbLb7fLx8VFoaKiCg4M1YcIEtWzZUn379lV4eLjWrFmjgoICPfzww479JCQkqGvX\nri78JAAAd8VT/hqBpj7O9WKids6hfuaonTlX3zxsorl/15zv5qidOWpnjto5h3uoAKAZ+93vblNp\naamSkt5QWtr+85aVlpbqd7+7rcbtf3pZ4gcfvKdPPvn4orUTANA8NcV+iiF/ANAERUZOrvc23357\nTJs3p2j48BEaPbrmDg0AAGc0pX6KQAUAbuAPf7hL8fGL1aVLF3333beaO3eW/PxsKisr0/fff6+Z\nMx9R377XONZfsGC+hg8foeuuG6DHH39U5eXl6t//OsfyjRs/1Nq1yfL09FDPnr302GOPa8mSBH35\nZbpWrkzU2bNn1aFDB91xxwS9+OLzOnBgn86cqdAdd4xXePgYRUffr+uvv0F79+5RYWGhEhL+qi5d\nuriiNACARqA591MEKgCoJ3vm/2j/zjRVnG24W1AH2Ppp3C9vrXZ5cPDN2r79U91xx3ht2/aJgoNv\nVq9evRUcPFz/+leq3nrrTS1Y8OwF26WkfKgrr+yl6dNnacuWjdq8+ccn4pWVlWnx4mXy8fHRtGn3\n6dChTE2cGCm7fY3uuec+vfbaK5Kkf/97r/7730N66aXXVVZWprvvjlBw8HBJkre3t55//iW99NIy\nffrpRxo//s4GqwcAwFzSv9/R9sP/atB90k9Vj0AFAG4gOPhmLV/+nO64Y7w+++wTRUfP1N//nqS/\n/S1Jp0+fVqtWrarc7ptv/qvrrhskSRowYJBjfrt27TR37ixJ0uHD/6uiosIqtz948D+67rqBkqTW\nrVurZ88rdfToUUnStdcOkPTju6CKiooa5oMCANxSc+6nCFQAUE/jfnmrHgiceEmfoHTllb2Ul5ej\n48e/U3FxsbZt26rOnW164okcTe6UAAAXOUlEQVQ4HTz4Hy1f/lyV21VWSh4eFknS2f+7onb69Gkt\nWfKM3njjbXXq1FmPPvpwldtKksVi0bnPgj1z5rRjf56enuccp1E8MBYAICnyujsU3u2WS3rM5txP\n8ZQ/AHATgYFDtWLFixo27CYVFRWqW7fukqRPPvlYZ86cqXKbHj1+oYMHv5Qk7d27R5JUWnpKnp6e\n6tSps44f/04HD36pM2fOyMPDQxUVFedtf/XVAfrii3/933alys7OUvfuPS7WRwQAuLHm2k/VKVBl\nZGRo5MiRWr169QXL1qxZo/HjxysiIkLz589XZWWldu3apRtvvFGRkZGKjIxUXFxcgzccAJqbm266\n2fF0o/DwMUpOfkszZ05TQMA1ysvL0/vvr79gm/DwMUpPP6AZM/6oo0cPy2KxqH37Drr++ht0771R\nWrkyUXfeGamlS5foF7+4Ql99dVBLly52bH/ttdepT5+rNW3afZo5c5qmTo1W69atL+XHBgC4ieba\nT9X6Yt/S0lI98MAD6tmzp/r06aNJkyY5lpWVlWnq1Kl69dVX1aJFC0VFRenhhx/W6dOn9dZbb2np\n0qV1bkhzfvkYL18zR+2cQ/3MUTtzvNjX/XC+m6N25qidOWrnnAZ/sa+Xl5cSExNls9kuWNa6dWu9\n+eabatGihcrKylRSUiI/P796NQAAAAAA3FWtD6WwWq2yWmtebcWKFVq1apWioqJ0+eWX69ixY8rM\nzNTUqVNVVFSk6OhoBQUF1bgPX982slo9a1ynKXPHX2wbC2rnHOpnjtoBAIAGecrf/fffr6ioKN13\n330aNGiQevbsqejoaI0aNUpHjx5VVFSUNm7cKC8vr2r3UVBQ2hBNcUtcljVH7ZxD/cxRO3MEUQBA\nU+LUU/4KCwuVmpoqSWrVqpWCg4O1d+9e+fv7a/To0bJYLOrRo4c6d+6s48ePN0iDAQAAAKCxcCpQ\nnTlzRnPmzNGpU6ckSQcOHNAVV1yh9evX67XXXpMk5eTkKC8vT/7+/s63FgAAAAAakVqH/KWlpSkh\nIUHZ2dmyWq1KSUlRSEiIunfvrtDQUE2bNk1RUVGyWq3q06ePRowYoVOnTmn27NnasmWLTp8+rfnz\n59c43A8AAAAA3FGtj02/VJrzvQjci2GO2jmH+pmjdubc8R6q5v5dc76bo3bmqJ05auecBn9sOgAA\nAACgagQqAAAAADBEoAIAAAAAQwQqAAAAADBEoAIAAAAAQwQqAAAAADBEoAIAAAAAQwQqAAAAADBE\noAIAAAAAQwQqAAAAADBEoAIAAAAAQwQqAAAAADBEoAIAAAAAQwQqAAAAADBEoAIAAAAAQwQqAAAA\nADBkdXUDAABwRnx8vPbt2yeLxaKYmBj179/fsSwkJERdunSRp6enJGnRokXy9/evcRsAAOqDQAUA\ncFu7d+/W4cOHlZycrEOHDikmJkbJycnnrZOYmChvb+96bQMAQF0x5A8A4LZ27NihkSNHSpJ69eql\noqIilZSUNPg2AABUh0AFAHBbubm58vX1dUx37NhROTk5560TGxuriRMnatGiRaqsrKzTNgAA1BVD\n/gAATUZlZeV509OnT9ewYcPUvn17TZs2TSkpKbVuUxVf3zayWj0brJ3uyM/Px9VNcFvUzhy1M0ft\nLh0CFQDAbdlsNuXm5jqmT5w4IT8/P8f02LFjHf8ODg5WRkZGrdtUpaCgtAFb7X78/HyUk1Ps6ma4\nJWpnjtqZo3bOqW8YZcgfAMBtBQUFOa46paeny2azqW3btpKk4uJiTZkyReXl5ZKk1NRU9e7du8Zt\nAACoL65QAQDc1sCBAxUQEKCIiAhZLBbFxsbKbrfLx8dHoaGhCg4O1oQJE9SyZUv17dtX4eHhslgs\nF2wDAIApS2UdBo9nZGTowQcf1OTJkzVp0qTzlq1Zs0Zr166Vh4eHrr76asXGxspisdT7HR/N+bIk\nl2XNUTvnUD9z1M6cO47rb+7fNee7OWpnjtqZo3bOqW8/VesVqtLSUsXFxSkwMPCCZWVlZXr//ff1\n1ltvqUWLFoqKitIXX3yhM2fO8I4PAAAAAE1erfdQeXl5KTExUTab7YJlrVu31ptvvqkWLVqorKxM\nJSUl8vPz4x0fAAAAAJqFWq9QWa1WWa01r7ZixQqtWrVKUVFRuvzyy5Wbm6uAgADH8p/e8VHTTb/N\n/ZG07jgEprGgds6hfuaoHQAAaJCHUtx///2KiorSfffdp0GDBl2wvC7v+GjOj6RlnKs5aucc6meO\n2pkjiAIAmhKnHpteWFio1NRUSVKrVq0UHBysvXv3Gr3jAwAAAADcjVOB6syZM5ozZ45OnTolSTpw\n4ICuuOIK3vEBAAAAoFmodchfWlqaEhISlJ2dLavVqpSUFIWEhKh79+4KDQ3VtGnTFBUVJavVqj59\n+mjEiBG84wMAAABAs1Cn91BdCs35XgTuxTBH7ZxD/cxRO3PueA9Vc/+uOd/NUTtz1M4ctXNOffsp\np4b8AQAAAEBzRqACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKAC\nAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAw\nRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAAAAAwRKACAAAAAEMEKgAA\nAAAwRKACAAAAAEN1ClQZGRkaOXKkVq9efcGynTt3avz48YqIiNDcuXN19uxZ7dq1SzfeeKMiIyMV\nGRmpuLi4Bm84AAAAALiatbYVSktLFRcXp8DAwCqXP/nkk1q1apW6dOmi6dOna9u2bWrVqpUGDx6s\npUuXNniDAQA4V3x8vPbt2yeLxaKYmBj179//gnUWL16sf//730pKStKpU6f02GOPqaioSKdPn9a0\nadM0bNgwF7QcANAU1HqFysvLS4mJibLZbFUut9vt6tKliySpY8eOKigoaNgWAgBQjd27d+vw4cNK\nTk7WggULtGDBggvWyczMVGpqqmP63Xff1RVXXKGkpCQ9//zzVW4DAEBd1XqFymq1ymqtfrW2bdtK\nkk6cOKHt27drxowZysjIUGZmpqZOnaqioiJFR0crKCioxuP4+raR1epZz+Y3HX5+Pq5ugtuids6h\nfuaonevt2LFDI0eOlCT16tVLRUVFKikpcfRNkrRw4ULNnDlTy5cvlyT5+vrqq6++kiSdPHlSvr6+\nl77hAIAmo9ZAVRd5eXmaOnWqYmNj5evrq549eyo6OlqjRo3S0aNHFRUVpY0bN8rLy6vafRQUlDZE\nU9ySn5+PcnKKXd0Mt0TtnEP9zFE7cw0ZRHNzcxUQEOCY7tixo3JychyBym63a/DgwerWrZtjnTFj\nxshutys0NFQnT57UK6+8UutxmvuPfhI/IDiD2pmjduao3aXjdKAqKSnRfffdp4cfflhDhw6VJPn7\n+2v06NGSpB49eqhz5846fvy4Lr/8cmcPBwBAtSorKx3/LiwslN1u18qVK3X8+HHH/H/+85/q2rWr\nXnvtNR08eFAxMTGy2+017rc5/+gn8QOCM6idOWpnjto5p75h1OlAtXDhQt19990KDg52zFu/fr1y\ncnI0ZcoU5eTkKC8vT/7+/s4eCgCA89hsNuXm5jqmT5w4IT8/P0k/PoU2Pz9fd911l8rLy3XkyBHF\nx8frhx9+cPwAePXVV+vEiROqqKiQp2fzvgIFADBTa6BKS0tTQkKCsrOzZbValZKSopCQEHXv3l1D\nhw7VunXrdPjwYa1du1aSdOutt2rMmDGaPXu2tmzZotOnT2v+/Pk1DvcDAMBEUFCQli1bpoiICKWn\np8tmszmG+4WHhys8PFySlJWVpblz5yomJkavv/669u3bp7CwMGVnZ8vb25swBQAwVmuguuaaa5SU\nlFTt8rS0tCrnv/zyy+atAgCgDgYOHKiAgABFRETIYrEoNjZWdrtdPj4+Cg0NrXKbCRMmKCYmRpMm\nTdKZM2c0f/78S9toAECTYqk8d8C5CzXncZ6MczVH7ZxD/cxRO3PueKN0c/+uOd/NUTtz1M4ctXNO\nffupWt9DBQAAAACoGoEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAAAADA\nEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAA\nAADAEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwRqAAAAADAEIEKAAAAAAwR\nqAAAAADAUJ0CVUZGhkaOHKnVq1dfsGznzp0aP368IiIiNHfuXJ09e1aSFB8frwkTJigiIkL79+9v\n2FYDAAAAQCNgrW2F0tJSxcXFKTAwsMrlTz75pFatWqUuXbpo+vTp2rZtm1q3bq3Dhw8rOTlZhw4d\nUkxMjJKTkxu88QAAAADgSrVeofLy8lJiYqJsNluVy+12u7p06SJJ6tixowoKCrRjxw6NHDlSktSr\nVy8VFRWppKSkAZsNAAAAAK5X6xUqq9Uqq7X61dq2bStJOnHihLZv364ZM2ZoyZIlCggIcKzTsWNH\n5eTkONatiq9vG1mtnvVpe5Pi5+fj6ia4LWrnHOpnjtoBAIBaA1Vd5OXlaerUqYqNjZWvr+8Fyysr\nK2vdR0FBaUM0xS35+fkoJ6fY1c1wS9TOOdTPHLUzRxAFADQlTj/lr6SkRPfdd58efvhhDR06VJJk\ns9mUm5vrWOfEiRPy8/Nz9lAAAAAA0Kg4HagWLlyou+++W8HBwY55QUFBSklJkSSlp6fLZrPVONwP\nAAAAANxRrUP+0tLSlJCQoOzsbFmtVqWkpCgkJETdu3fX0KFDtW7dOh0+fFhr166VJN16662aMGGC\nAgICFBERIYvFotjY2Iv+QQAAAADgUqs1UF1zzTVKSkqqdnlaWlqV82fPnm3eKgAAAABwA04P+QMA\nwJXq8iL5xYsXKzIy0jG9fv16/eY3v9G4ceO0devWS9RSAEBTRKACALit3bt3O14kv2DBAi1YsOCC\ndTIzM5WamuqYLigo0AsvvKC3335bL7/8srZs2XIpmwwAaGIIVAAAt1WXF8kvXLhQM2fOPG+bwMBA\ntW3bVjabTXFxcZe0zQCApqVB3kMFAIAr5Obm1vgiebvdrsGDB6tbt26OdbKysvT9999r6tSpOnny\npB566CEFBgbWeJzm/vJ5ifeHOYPamaN25qjdpUOgAgA0Gee+SL6wsFB2u10rV67U8ePHz1uvsLBQ\ny5cv17FjxxQVFaWPP/5YFoul2v0255fPS7zI2hnUzhy1M0ftnFPfMNpoAlVzT9HN/fM7g9o5h/qZ\no3auV9OL5Hfu3Kn8/HzdddddKi8v15EjRxQfH68+ffpowIABslqt6tGjh7y9vZWfn69OnTpVexy+\na2rgDGpnjtqZo3aXDvdQAQDcVk0vkg8PD9cHH3ygNWvWaPny5QoICFBMTIyGDh2qnTt36uzZsyoo\nKFBpaal8fX1d+TEAAG6s0VyhAgCgvgYOHHjBi+Ttdrt8fHwUGhpa5Tb+/v4KCwvT+PHjJUnz5s2T\nhwe/LwIAzFgqzx1wDgAAAACoM36SAwAAAABDBCoAAAAAMESgAgAAAABDBCoAAAAAMMRT/lxo165d\nmjFjhnr37i1Juuqqq/TEE0+4uFWNX0ZGhh588EFNnjxZkyZN0rfffqtHH31UFRUV8vPz07PPPisv\nLy9XN7NR+nnt5syZo/T0dHXo0EGSNGXKFA0fPty1jWyknnnmGf3rX//SmTNn9MADD6hfv36cd3X0\n89p99NFHnHdugD7KDH2UOfooc/RRznG2nyJQudjgwYO1dOlSVzfDbZSWliouLk6BgYGOeUuXLtWd\nd96pUaNGacmSJVq7dq3uvPNOF7aycaqqdpL0pz/9STfffLOLWuUedu7cqa+//lrJyckqKCjQb3/7\nWwUGBnLe1UFVtbvxxhs579wEfVT90EeZo48yRx/lnIbopxjyB7fi5eWlxMRE2Ww2x7xdu3ZpxIgR\nkqSbb75ZO3bscFXzGrWqaoe6uf766/X8889Lktq1a6eysjLOuzqqqnYVFRUubhVwcdBHmaOPMkcf\n5ZyG6KcIVC6WmZmpqVOnauLEidq+fburm9PoWa1WtWrV6rx5ZWVljsvYnTp1Uk5Ojiua1uhVVTtJ\nWr16taKiojRz5kzl5+e7oGWNn6enp9q0aSNJWrt2rYKDgznv6qiq2nl6enLeuQn6qPqhjzJHH2WO\nPso5DdFPMeTPhXr27Kno6GiNGjVKR48eVVRUlDZu3MgYVyfwnur6uf3229WhQwf96le/0ooVK7R8\n+XI9+eSTrm5Wo7V582atXbtWr7/+um655RbHfM672p1bu7S0NM47N0Af1fD4W1E/9FH1Qx/lHGf6\nKa5QuZC/v79Gjx4ti8WiHj16qHPnzjp+/Lirm+V22rRpo++//16SdPz4cYYL1ENgYKB+9atfSZJC\nQkKUkZHh4hY1Xtu2bdPLL7+sxMRE+fj4cN7Vw89rx3nnHuijGgZ/K8zxt6Lu6KOc42w/RaByofXr\n1+u1116TJOXk5CgvL0/+/v4ubpX7GTJkiFJSUiRJGzdu1LBhw1zcIvfx0EMP6ejRo5J+HOf/09O8\ncL7i4mI988wzeuWVVxxP/OG8q5uqasd55x7ooxoGfyvM8beibuijnNMQ/ZSlkuuALlNSUqLZs2fr\n5MmTOn36tKKjo3XTTTe5ulmNWlpamhISEpSdnS2r1Sp/f38tWrRIc+bM0Q8//KCuXbvq6aefVosW\nLVzd1EanqtpNmjRJK1asUOvWrdWmTRs9/fTT6tSpk6ub2ugkJydr2bJluuKKKxzzFi5cqHnz5nHe\n1aKq2o0bN06rV6/mvGvk6KPqjz7KHH2UOfoo5zREP0WgAgAAAABDDPkDAAAAAEMEKgAAAAAwRKAC\nAAAAAEMEKgAAAAAwRKACAAAAAEMEKqARs9vtmj17tqubAQBAleinAAIVAAAAABizuroBQFOQlJSk\nDz/8UBUVFbryyit177336oEHHlBwcLAOHjwoSfrrX/8qf39/bd26VS+88IJatWql1q1bKy4uTv7+\n/tq3b5/i4+PVokULtW/fXgkJCZL+/8s1Dx06pK5du2r58uWyWCyu/LgAADdDPwVcPFyhApy0f/9+\nbdq0SW+99ZaSk5Pl4+Ojzz//XEePHtW4ceP09ttva/DgwXr99ddVVlamefPmadmyZUpKSlJwcLCe\ne+45SdIjjzyiuLg4rV69Wtdff70++eQTSVJmZqbi4uJkt9v19ddfKz093ZUfFwDgZuingIuLK1SA\nk3bt2qUjR44oKipKklRaWqrjx4+rQ4cOuuaaayRJAwcO1JtvvqlvvvlGnTp1UpcuXSRJgwcP1t//\n/nfl5+fr5MmTuuqqqyRJkydPlvTj2PR+/fqpdevWkiR/f38VFxdf4k8IAHBn9FPAxUWgApzk5eWl\nkJAQPfnkk455WVlZGjdunGO6srJSFovlgiEQ586vrKyscv+enp4XbAMAQF3RTwEXF0P+ACcNHDhQ\nn376qU6dOiVJeuutt5STk6OioiL95z//kSTt3btXffr0Uc+ePZWXl6djx45Jknbs2KFrr71Wvr6+\n6tChg/bv3y9Jev311/XWW2+55gMBAJoU+ing4uIKFeCkfv366a677lJkZKRatmwpm82mG264Qf7+\n/rLb7Vq4cKEqKyu1ZMkStWrVSgsWLNDMmTPl5eWlNm3aaMGCBZKkZ599VvHx8bJarfLx8dGzzz6r\njRs3uvjTAQDcHf0UcHFZKrkuCzS4rKws3Xnnnfr0009d3RQAAC5APwU0HIb8AQAAAIAhrlABAAAA\ngCGuUAEAAACAIQIVAAAAABgiUAEAAACAIQIVAAAAABgiUAEAAACAof8H9ezEmrdSX1IAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc6da236400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/25\n",
            " 20/781 [..............................] - ETA: 8:58 - loss: 1.2219 - acc: 0.5805"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-dbfdd3881aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     callbacks=[PlotLossesKeras(), EarlyStopping(patience=4)])\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4071sG5o_WuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "so now we have run the same model with different dropout numbers for the convulutional layers. so lets compare:"
      ]
    },
    {
      "metadata": {
        "id": "-sZEU-wR9Ca2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "\n",
        "for dropout, hist in zip(dropouts, history):\n",
        "  plt.plot(history.history['acc'], label=f\"dropout_{dropout}\", ls=\"dashed\", lw=1, alpha=0.8)\n",
        "  plt.plot(history.history['val_acc'], label=f\"dropout_{dropout}\", ls=\"solid\", lw=2)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0iN2lhnhxUr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "what beautiful graphs! especially compared to the version without dropout.\n",
        "\n",
        "its quite clear from the losses and accuracy that adding dropout has an  important impact on the NN. in particular:\n",
        "\n",
        "- with dropout, the model starts at a lower accuracy, but thats expected as there is less information passing through\n",
        "- its no longer overfitting, so can train longer and get better results. I stopped it early but it can be tweaked to train longer.\n",
        "- accuracy has increased, though not by much. \n",
        "- our simple model still starts overfitting, though later than before.\n",
        "\n",
        "So dropout is a clear winner here, though of course it depends on the problem. there are a number of papers exploring effects of dropout on differrent problems. \n"
      ]
    },
    {
      "metadata": {
        "id": "k2XGoS2PEZeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}